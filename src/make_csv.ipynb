{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7154e34f",
   "metadata": {},
   "source": [
    "# Convert and concatenate netCDF data into CSV\n",
    "https://cds-beta.climate.copernicus.eu/datasets/sis-ecde-climate-indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28c427fc-2563-4f2a-b7fe-65ce3fde1133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdsapi\n",
    "import zipfile\n",
    "import netCDF4\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0a1d03",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bc6206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_unpack_data(dataset, request, dir_name):\n",
    "    path_to_zip_file = f'{dir_name}.zip'\n",
    "    directory_to_extract_to = f'data/{dir_name}'\n",
    "\n",
    "    client = cdsapi.Client()\n",
    "    client.retrieve(dataset, request, f'{dir_name}.zip')\n",
    "\n",
    "    with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(directory_to_extract_to)\n",
    "        os.remove(path_to_zip_file)\n",
    "\n",
    "    file_names = os.listdir(f'data/{dir_name}')\n",
    "\n",
    "    return file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b55c9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nc_file(file_name, dir_name):\n",
    "    \n",
    "    path_to_file = f'data/{dir_name}/{file_name}'\n",
    "    file2read = netCDF4.Dataset(path_to_file,'r')\n",
    "    keys = file2read.variables.keys()\n",
    "\n",
    "    print(keys)\n",
    "    print(file2read)\n",
    "    #data = file2read.variables['time'][:]\n",
    "    #print(data)\n",
    "    print('\\n\\n\\n')\n",
    "\n",
    "    file2read.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f036a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_lat_lon(file_name, dir_name):\n",
    "    \n",
    "    path_to_file = f'data/{dir_name}/{file_name}'\n",
    "    file2read = netCDF4.Dataset(path_to_file,'r')\n",
    "\n",
    "    time = file2read.variables['time'][:]\n",
    "    lat = file2read.variables['lat'][:]\n",
    "    lon = file2read.variables['lon'][:]\n",
    "\n",
    "    file2read.close()\n",
    "    \n",
    "    return time, lat, lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1739a149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_by_key(file_name, key, dir_name):\n",
    "    \n",
    "    path_to_file = f'data/{dir_name}/{file_name}'\n",
    "    file2read = netCDF4.Dataset(path_to_file,'r')\n",
    "\n",
    "    val = file2read.variables[key][:]\n",
    "    print(val)\n",
    "    file2read.close()\n",
    "    \n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a516e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_unique_vals(arr):\n",
    "    arr.ravel()\n",
    "    arr = np.array(arr)\n",
    "    print(np.unique(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7b17d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_3D(matrix):\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(matrix.shape[1]):\n",
    "            for k in range(matrix.shape[2]):\n",
    "                yield i, j, k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5dcc2d",
   "metadata": {},
   "source": [
    "### Reanalysis Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d480e17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'reanalysis'\n",
    "\n",
    "dataset = \"sis-ecde-climate-indicators\"\n",
    "\n",
    "request = {\n",
    "    'variable': ['mean_temperature', 'hot_days', 'frost_days', 'duration_of_meteorological_droughts'],\n",
    "    'origin': 'reanalysis',\n",
    "    'temporal_aggregation': ['yearly'],\n",
    "    'spatial_aggregation': 'gridded',\n",
    "    'other_parameters': ['30_c']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ca95f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-14 18:16:16,356 INFO Request ID is 04cfbfa4-0486-4834-bde7-712d682fc67e\n",
      "2024-09-14 18:16:16,413 INFO status has been updated to accepted\n",
      "2024-09-14 18:16:17,974 INFO status has been updated to running\n",
      "2024-09-14 18:16:20,279 INFO status has been updated to successful\n",
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['lat', 'lon', 'realization', 'time', 'dmd'])\n",
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    dimensions(sizes): lat(185), lon(271), time(84)\n",
      "    variables(dimensions): float64 lat(lat), float64 lon(lon), int64 realization(), int64 time(time), int64 dmd(time, lat, lon)\n",
      "    groups: \n",
      "[    0   366   731  1096  1461  1827  2192  2557  2922  3288  3653  4018\n",
      "  4383  4749  5114  5479  5844  6210  6575  6940  7305  7671  8036  8401\n",
      "  8766  9132  9497  9862 10227 10593 10958 11323 11688 12054 12419 12784\n",
      " 13149 13515 13880 14245 14610 14976 15341 15706 16071 16437 16802 17167\n",
      " 17532 17898 18263 18628 18993 19359 19724 20089 20454 20820 21185 21550\n",
      " 21915 22281 22646 23011 23376 23742 24107 24472 24837 25203 25568 25933\n",
      " 26298 26664 27029 27394 27759 28125 28490 28855 29220 29586 29951 30316]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dict_keys(['time', 'realization', 'lat', 'lon', 't2m'])\n",
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    Conventions: CF-1.7\n",
      "    institution: European Centre for Medium-Range Weather Forecasts\n",
      "    history: 2024-04-02T13:52 GRIB to CDM+CF via cfgrib-0.9.9.1/ecCodes-2.27.0 with {\"source\": \"/nfs/compute-0014/data3/adaptor.mars.internal-1712065708.8353992-6424-6-39247118-b7b6-4b87-8957-46d0ba425a8f.grib\", \"filter_by_keys\": {}, \"encode_cf\": [\"parameter\", \"time\", \"geography\", \"vertical\"]}\n",
      "    source: ECMWF\n",
      "    dimensions(sizes): time(84), lat(185), lon(271)\n",
      "    variables(dimensions): int64 time(time), int64 realization(), float64 lat(lat), float64 lon(lon), float32 t2m(time, lat, lon)\n",
      "    groups: \n",
      "[    0   366   731  1096  1461  1827  2192  2557  2922  3288  3653  4018\n",
      "  4383  4749  5114  5479  5844  6210  6575  6940  7305  7671  8036  8401\n",
      "  8766  9132  9497  9862 10227 10593 10958 11323 11688 12054 12419 12784\n",
      " 13149 13515 13880 14245 14610 14976 15341 15706 16071 16437 16802 17167\n",
      " 17532 17898 18263 18628 18993 19359 19724 20089 20454 20820 21185 21550\n",
      " 21915 22281 22646 23011 23376 23742 24107 24472 24837 25203 25568 25933\n",
      " 26298 26664 27029 27394 27759 28125 28490 28855 29220 29586 29951 30316]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dict_keys(['time', 'realization', 'lat', 'lon', 't2m'])\n",
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    dimensions(sizes): time(84), lat(185), lon(271)\n",
      "    variables(dimensions): int64 time(time), int64 realization(), float64 lat(lat), float64 lon(lon), int64 t2m(time, lat, lon)\n",
      "    groups: \n",
      "[    0   366   731  1096  1461  1827  2192  2557  2922  3288  3653  4018\n",
      "  4383  4749  5114  5479  5844  6210  6575  6940  7305  7671  8036  8401\n",
      "  8766  9132  9497  9862 10227 10593 10958 11323 11688 12054 12419 12784\n",
      " 13149 13515 13880 14245 14610 14976 15341 15706 16071 16437 16802 17167\n",
      " 17532 17898 18263 18628 18993 19359 19724 20089 20454 20820 21185 21550\n",
      " 21915 22281 22646 23011 23376 23742 24107 24472 24837 25203 25568 25933\n",
      " 26298 26664 27029 27394 27759 28125 28490 28855 29220 29586 29951 30316]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dict_keys(['time', 'realization', 'lat', 'lon', 't2m'])\n",
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    dimensions(sizes): time(84), lat(185), lon(271)\n",
      "    variables(dimensions): int64 time(time), int64 realization(), float64 lat(lat), float64 lon(lon), int64 t2m(time, lat, lon)\n",
      "    groups: \n",
      "[    0   366   731  1096  1461  1827  2192  2557  2922  3288  3653  4018\n",
      "  4383  4749  5114  5479  5844  6210  6575  6940  7305  7671  8036  8401\n",
      "  8766  9132  9497  9862 10227 10593 10958 11323 11688 12054 12419 12784\n",
      " 13149 13515 13880 14245 14610 14976 15341 15706 16071 16437 16802 17167\n",
      " 17532 17898 18263 18628 18993 19359 19724 20089 20454 20820 21185 21550\n",
      " 21915 22281 22646 23011 23376 23742 24107 24472 24837 25203 25568 25933\n",
      " 26298 26664 27029 27394 27759 28125 28490 28855 29220 29586 29951 30316]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_names = get_and_unpack_data(dataset, request, dir_name)\n",
    "\n",
    "for name in file_names:\n",
    "    read_nc_file(name, dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b02d8411",
   "metadata": {},
   "outputs": [],
   "source": [
    "### REMEMBER TO ADJUST NUMBER OF FILES AND GIVE APPROPIATE KEY NAMES!!!\n",
    "time, lat, lon = get_time_lat_lon(file_names[0], dir_name)\n",
    "\n",
    "mean_temperature = get_val_by_key(file_names[1], 't2m', dir_name)\n",
    "hot_days = get_val_by_key(file_names[3], 't2m', dir_name)\n",
    "frost_days = get_val_by_key(file_names[2], 't2m', dir_name)\n",
    "droughts = get_val_by_key(file_names[0], 'dmd', dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd0fbc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILE_NAME = 'reanalysis.csv'\n",
    "l = []\n",
    "\n",
    "l.append('time,lat,lon,mean_t,hot_d,cold_d,droughts')\n",
    "\n",
    "for i, j, k in iter_3D(mean_temperature):\n",
    "    l.append('%d,%.2f,%.2f,%.2f,%d,%d,%d' %((time[i]/365 + 1940), lat[j], lon[k],\n",
    "                                    mean_temperature[i, j, k]-273.15,\n",
    "                                    hot_days[i, j, k],\n",
    "                                    frost_days[i, j, k],\n",
    "                                    droughts[i, j, k]))\n",
    "\n",
    "with open(OUTPUT_FILE_NAME, 'w') as f:\n",
    "    f.write(\"\\n\".join(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6420ba95",
   "metadata": {},
   "source": [
    "### Projections Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d9df34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'projections'\n",
    "\n",
    "dataset = \"sis-ecde-climate-indicators\"\n",
    "\n",
    "## mean: --, hot_days: 0, frost_days: --, droughts: --\n",
    "# request = {\n",
    "#     'variable': ['mean_temperature', 'hot_days', 'frost_days', 'duration_of_meteorological_droughts'],\n",
    "#     'origin': 'projections',\n",
    "#     'gcm': ['mpi_esm_lr'],\n",
    "#     'rcm': ['cclm4_8_17'],\n",
    "#     'experiment': ['rcp8_5'],\n",
    "#     'ensemble_member': ['r1i1p1'],\n",
    "#     'temporal_aggregation': ['yearly'],\n",
    "#     'spatial_aggregation': 'gridded',\n",
    "#     'other_parameters': ['30_c']\n",
    "# }\n",
    "\n",
    "request = {\n",
    "    'variable': ['mean_temperature', 'hot_days', 'frost_days', 'duration_of_meteorological_droughts'],\n",
    "    'origin': 'projections',\n",
    "    'gcm': ['ec_earth'],\n",
    "    'rcm': ['hirham5'],\n",
    "    'experiment': ['rcp4_5'],\n",
    "    'ensemble_member': ['r3i1p1'],\n",
    "    'temporal_aggregation': ['yearly'],\n",
    "    'spatial_aggregation': 'gridded',\n",
    "    'other_parameters': ['40_c']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f6f393a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-14 20:25:52,153 INFO Request ID is 94b66ead-d5f3-4bba-8b45-1ab96d79b901\n",
      "2024-09-14 20:25:52,207 INFO status has been updated to accepted\n",
      "2024-09-14 20:25:53,769 INFO status has been updated to running\n",
      "2024-09-14 20:25:56,086 INFO status has been updated to successful\n",
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['lat', 'lon', 'time', 'dmd'])\n",
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    dimensions(sizes): lat(185), lon(271), time(150)\n",
      "    variables(dimensions): float64 lat(lat), float64 lon(lon), int64 time(time), int64 dmd(time, lat, lon)\n",
      "    groups: \n",
      "[    0   365   731  1096  1461  1826  2192  2557  2922  3287  3653  4018\n",
      "  4383  4748  5114  5479  5844  6209  6575  6940  7305  7670  8036  8401\n",
      "  8766  9131  9497  9862 10227 10592 10958 11323 11688 12053 12419 12784\n",
      " 13149 13514 13880 14245 14610 14975 15341 15706 16071 16436 16802 17167\n",
      " 17532 17897 18263 18628 18993 19358 19724 20089 20454 20819 21185 21550\n",
      " 21915 22280 22646 23011 23376 23741 24107 24472 24837 25202 25568 25933\n",
      " 26298 26663 27029 27394 27759 28124 28490 28855 29220 29585 29951 30316\n",
      " 30681 31046 31412 31777 32142 32507 32873 33238 33603 33968 34334 34699\n",
      " 35064 35429 35795 36160 36525 36890 37256 37621 37986 38351 38717 39082\n",
      " 39447 39812 40178 40543 40908 41273 41639 42004 42369 42734 43100 43465\n",
      " 43830 44195 44561 44926 45291 45656 46022 46387 46752 47117 47483 47848\n",
      " 48213 48578 48944 49309 49674 50039 50405 50770 51135 51500 51866 52231\n",
      " 52596 52961 53327 53692 54057 54422]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dict_keys(['time', 'lat', 'lon', 'height', 'tasAdjust_NON_CDM'])\n",
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    dimensions(sizes): time(150), lat(185), lon(271)\n",
      "    variables(dimensions): int64 time(time), float64 lat(lat), float64 lon(lon), float64 height(), float64 tasAdjust_NON_CDM(time, lat, lon)\n",
      "    groups: \n",
      "[    0   365   731  1096  1461  1826  2192  2557  2922  3287  3653  4018\n",
      "  4383  4748  5114  5479  5844  6209  6575  6940  7305  7670  8036  8401\n",
      "  8766  9131  9497  9862 10227 10592 10958 11323 11688 12053 12419 12784\n",
      " 13149 13514 13880 14245 14610 14975 15341 15706 16071 16436 16802 17167\n",
      " 17532 17897 18263 18628 18993 19358 19724 20089 20454 20819 21185 21550\n",
      " 21915 22280 22646 23011 23376 23741 24107 24472 24837 25202 25568 25933\n",
      " 26298 26663 27029 27394 27759 28124 28490 28855 29220 29585 29951 30316\n",
      " 30681 31046 31412 31777 32142 32507 32873 33238 33603 33968 34334 34699\n",
      " 35064 35429 35795 36160 36525 36890 37256 37621 37986 38351 38717 39082\n",
      " 39447 39812 40178 40543 40908 41273 41639 42004 42369 42734 43100 43465\n",
      " 43830 44195 44561 44926 45291 45656 46022 46387 46752 47117 47483 47848\n",
      " 48213 48578 48944 49309 49674 50039 50405 50770 51135 51500 51866 52231\n",
      " 52596 52961 53327 53692 54057 54422]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dict_keys(['time', 'lat', 'lon', 'height', 'tasAdjust_NON_CDM'])\n",
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    dimensions(sizes): time(150), lat(185), lon(271)\n",
      "    variables(dimensions): int64 time(time), float64 lat(lat), float64 lon(lon), float64 height(), float64 tasAdjust_NON_CDM(time, lat, lon)\n",
      "    groups: \n",
      "[    0   365   731  1096  1461  1826  2192  2557  2922  3287  3653  4018\n",
      "  4383  4748  5114  5479  5844  6209  6575  6940  7305  7670  8036  8401\n",
      "  8766  9131  9497  9862 10227 10592 10958 11323 11688 12053 12419 12784\n",
      " 13149 13514 13880 14245 14610 14975 15341 15706 16071 16436 16802 17167\n",
      " 17532 17897 18263 18628 18993 19358 19724 20089 20454 20819 21185 21550\n",
      " 21915 22280 22646 23011 23376 23741 24107 24472 24837 25202 25568 25933\n",
      " 26298 26663 27029 27394 27759 28124 28490 28855 29220 29585 29951 30316\n",
      " 30681 31046 31412 31777 32142 32507 32873 33238 33603 33968 34334 34699\n",
      " 35064 35429 35795 36160 36525 36890 37256 37621 37986 38351 38717 39082\n",
      " 39447 39812 40178 40543 40908 41273 41639 42004 42369 42734 43100 43465\n",
      " 43830 44195 44561 44926 45291 45656 46022 46387 46752 47117 47483 47848\n",
      " 48213 48578 48944 49309 49674 50039 50405 50770 51135 51500 51866 52231\n",
      " 52596 52961 53327 53692 54057 54422]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dict_keys(['time', 'lat', 'lon', 'height', 'tasAdjust'])\n",
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    CORDEX_domain: EUR-25\n",
      "    driving_model_id: ICHEC-EC-EARTH\n",
      "    driving_model_ensemble_member: r3i1p1\n",
      "    driving_experiment_name: rcp45\n",
      "    rcm_version_id: v1\n",
      "    bc_method: 'Vrac, M., NoÃ«l, T. and R. Vautard, 2016: Bias correction of precipitation through Singularity Stochastic Removal: Because occurrences matter, J. Geophys. Res., 121(10), 5237-5258.'\n",
      "    bc_method_id: IPSL-CDFT22\n",
      "    bc_observation: https://confluence.ecmwf.int/display/CKB/ERA5+data+documentation\n",
      "    bc_observation_id: ERA5\n",
      "    bc_period: 1980-2018\n",
      "    bc_info: IPSL-CDFT22-ERA5-1980-2018\n",
      "    input_tracking_id: unknown\n",
      "    input_institution: Danish Meteorological Institute\n",
      "    input_institute_id: DMI\n",
      "    institution: 'IPSL (Institut Pierre Simon Laplace)'\n",
      "    institute_id: IPSL\n",
      "    experiment_id: rcp45\n",
      "    source: HIRHAM5\n",
      "    model_id: DMI-HIRHAM5\n",
      "    forcing: N/A\n",
      "    contact: 'robert.vautard@lsce.ipsl.fr Data manager : Robert VAUTARD - Guillaume Lavavasseur - Xia JIN'\n",
      "    references: 'Bartok, B., Tobin, I., Vautard, R., Vrac, M., Jin, X., Levavasseur, G., Denvil, S., Dubus, L., Parey, S., Michelangeli, P.-A., Troccoli, A., and Y.-M. Saint Drenan, 2019: A climate projection dataset tailored for the energy sector. Climate Services, in press.'\n",
      "    initialization_method: 1\n",
      "    physics_version: 1\n",
      "    product: bias-adjusted-output\n",
      "    experiment: RCP4.5\n",
      "    frequency: 3hr\n",
      "    creation_date: 2020-02-14T17:39:16Z\n",
      "    history: 2020-02-14T17:39:16Z CMOR rewrote data to comply with CF standards and CORDEX-Adjust requirements.\n",
      "    Conventions: CF-1.4\n",
      "    project_id: CORDEX-Adjust\n",
      "    table_id: Table 3h (May 2016) 6cb98ba9d88fc3a3550aacd5e20414a2\n",
      "    title: DMI-HIRHAM5 model output prepared for CORDEX-Adjust RCP4.5\n",
      "    modeling_realm: atmos\n",
      "    realization: 3\n",
      "    cmor_version: 2.9.3\n",
      "    tracking_id: hdl:21.14104/ff00b31b-9f66-4e90-9417-1be6f30f9d7a\n",
      "    dimensions(sizes): time(150), lat(185), lon(271)\n",
      "    variables(dimensions): int64 time(time), float64 lat(lat), float64 lon(lon), float64 height(), float32 tasAdjust(time, lat, lon)\n",
      "    groups: \n",
      "[    0   365   731  1096  1461  1826  2192  2557  2922  3287  3653  4018\n",
      "  4383  4748  5114  5479  5844  6209  6575  6940  7305  7670  8036  8401\n",
      "  8766  9131  9497  9862 10227 10592 10958 11323 11688 12053 12419 12784\n",
      " 13149 13514 13880 14245 14610 14975 15341 15706 16071 16436 16802 17167\n",
      " 17532 17897 18263 18628 18993 19358 19724 20089 20454 20819 21185 21550\n",
      " 21915 22280 22646 23011 23376 23741 24107 24472 24837 25202 25568 25933\n",
      " 26298 26663 27029 27394 27759 28124 28490 28855 29220 29585 29951 30316\n",
      " 30681 31046 31412 31777 32142 32507 32873 33238 33603 33968 34334 34699\n",
      " 35064 35429 35795 36160 36525 36890 37256 37621 37986 38351 38717 39082\n",
      " 39447 39812 40178 40543 40908 41273 41639 42004 42369 42734 43100 43465\n",
      " 43830 44195 44561 44926 45291 45656 46022 46387 46752 47117 47483 47848\n",
      " 48213 48578 48944 49309 49674 50039 50405 50770 51135 51500 51866 52231\n",
      " 52596 52961 53327 53692 54057 54422]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_names = get_and_unpack_data(dataset, request, dir_name)\n",
    "\n",
    "for name in file_names:\n",
    "    read_nc_file(name, dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95d6928a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['19_duration_of_meteorological_droughts-projections-yearly-rcp_4_5-hirham5-ec_earth-r3i1p1-grid-v1.0.nc', '11_frost_days-projections-yearly-rcp_4_5-hirham5-ec_earth-r3i1p1-grid-v1.0.nc', '06_hot_days-projections-yearly-40deg-rcp_4_5-hirham5-ec_earth-r3i1p1-grid-v1.0.nc', '01_mean_temperature-projections-yearly-rcp_4_5-hirham5-ec_earth-r3i1p1-grid-v1.0.nc']\n"
     ]
    }
   ],
   "source": [
    "print(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14e8b5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "### REMEMBER TO ADJUST NUMBER OF FILES AND GIVE APPROPIATE KEY NAMES!!!\n",
    "time, lat, lon = get_time_lat_lon(file_names[0], dir_name)\n",
    "\n",
    "mean_temperature = get_val_by_key(file_names[3], 'tasAdjust', dir_name)\n",
    "hot_days = get_val_by_key(file_names[2], 'tasAdjust_NON_CDM', dir_name)\n",
    "frost_days = get_val_by_key(file_names[1], 'tasAdjust_NON_CDM', dir_name)\n",
    "droughts = get_val_by_key(file_names[0], 'dmd', dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90efdbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[264.56644 264.5857  264.59436 ... 304.28815 304.2906        nan]\n",
      "[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.\n",
      "  14.  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.\n",
      "  28.  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.\n",
      "  42.  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.\n",
      "  56.  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.\n",
      "  70.  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.\n",
      "  84.  85.  86.  87.  88.  89.  90.  91.  92.  93.  94.  95.  96.  97.\n",
      "  98.  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111.\n",
      " 112. 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125.\n",
      " 126. 127. 128. 129. 130. 131. 132. 133. 134. 135. 136. 137. 138. 139.\n",
      " 140. 141. 142. 143. 144. 145. 146. 147. 148. 149. 150. 151. 152. 153.\n",
      " 154. 155. 156. 157. 158. 159. 160. 161. 162. 163. 164. 165. 166. 167.\n",
      " 168. 169. 170. 171. 172. 173. 174. 175. 176. 177. 178. 179. 180. 181.\n",
      " 182. 183. 184. 185. 186. 187. 188. 189. 190. 192.  nan]\n",
      "[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.\n",
      "  14.  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.\n",
      "  28.  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.\n",
      "  42.  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.\n",
      "  56.  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.\n",
      "  70.  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.\n",
      "  84.  85.  86.  87.  88.  89.  90.  91.  92.  93.  94.  95.  96.  97.\n",
      "  98.  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111.\n",
      " 112. 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125.\n",
      " 126. 127. 128. 129. 130. 131. 132. 133. 134. 135. 136. 137. 138. 139.\n",
      " 140. 141. 142. 143. 144. 145. 146. 147. 148. 149. 150. 151. 152. 153.\n",
      " 154. 155. 156. 157. 158. 159. 160. 161. 162. 163. 164. 165. 166. 167.\n",
      " 168. 169. 170. 171. 172. 173. 174. 175. 176. 177. 178. 179. 180. 181.\n",
      " 182. 183. 184. 185. 186. 187. 188. 189. 190. 191. 192. 193. 194. 195.\n",
      " 196. 197. 198. 199. 200. 201. 202. 203. 204. 205. 206. 207. 208. 209.\n",
      " 210. 211. 212. 213. 214. 215. 216. 217. 218. 219. 220. 221. 222. 223.\n",
      " 224. 225. 226. 227. 228. 229. 230. 231. 232. 233. 234. 235. 236. 237.\n",
      " 238. 239. 240. 241. 242. 243. 244. 245. 246. 247. 248. 249. 250. 251.\n",
      " 252. 253. 254. 255. 256. 257. 258. 259. 260. 261. 262. 263. 264. 265.\n",
      " 266. 267. 268. 269. 270. 271. 272. 273. 274. 275. 276. 277. 278. 279.\n",
      " 280. 281. 282. 283. 284. 285. 286. 287. 288. 289. 290. 291. 292. 293.\n",
      " 294. 295. 296. 297. 298. 299. 300. 301. 302. 303. 304. 305. 306. 307.\n",
      " 308. 309. 310. 311. 312. 313. 314. 315. 316. 317. 318. 319. 320. 321.\n",
      " 322. 323. 324. 325. 326. 327. 328. 329. 330. 331. 332. 333. 334. 335.\n",
      " 336. 337. 338. 339. 340. 341. 342. 343. 344. 345. 346. 347. 348. 349.\n",
      " 350. 351. 352. 353. 354. 355. 357. 358.  nan]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n"
     ]
    }
   ],
   "source": [
    "show_unique_vals(mean_temperature)\n",
    "show_unique_vals(hot_days)\n",
    "show_unique_vals(frost_days)\n",
    "show_unique_vals(droughts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3a9f5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10207/1748182686.py:10: UserWarning: Warning: converting a masked element to nan.\n",
      "  l.append('%d,%.2f,%.2f,%.2f,%d,%d,%d' %((time[i]/365 + START_YEAR), lat[j], lon[k],\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_FILE_NAME = 'projections.csv'\n",
    "START_YEAR = 2100-151\n",
    "\n",
    "l = []\n",
    "\n",
    "l.append('time,lat,lon,mean_t,hot_d,cold_d,droughts')\n",
    "\n",
    "for i, j, k in iter_3D(mean_temperature):\n",
    "    try:\n",
    "        l.append('%d,%.2f,%.2f,%.2f,%d,%d,%d' %((time[i]/365 + START_YEAR), lat[j], lon[k],\n",
    "                                        mean_temperature[i, j, k]-273.15,\n",
    "                                        hot_days[i, j, k],\n",
    "                                        frost_days[i, j, k],\n",
    "                                        droughts[i, j, k]))\n",
    "    except np.ma.core.MaskError:\n",
    "        pass\n",
    "\n",
    "with open(OUTPUT_FILE_NAME, 'w') as f:\n",
    "    f.write(\"\\n\".join(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f637040",
   "metadata": {},
   "source": [
    "### Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "836587e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a39881db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"projections.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "523e966b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>mean_t</th>\n",
       "      <th>hot_d</th>\n",
       "      <th>cold_d</th>\n",
       "      <th>droughts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949</td>\n",
       "      <td>26.5</td>\n",
       "      <td>-12.25</td>\n",
       "      <td>18.86</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949</td>\n",
       "      <td>26.5</td>\n",
       "      <td>-12.00</td>\n",
       "      <td>18.70</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1949</td>\n",
       "      <td>26.5</td>\n",
       "      <td>-11.75</td>\n",
       "      <td>19.38</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1949</td>\n",
       "      <td>26.5</td>\n",
       "      <td>-11.50</td>\n",
       "      <td>19.92</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1949</td>\n",
       "      <td>26.5</td>\n",
       "      <td>-11.25</td>\n",
       "      <td>20.13</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time   lat    lon  mean_t  hot_d  cold_d  droughts\n",
       "0  1949  26.5 -12.25   18.86      8       0         4\n",
       "1  1949  26.5 -12.00   18.70      9       0         2\n",
       "2  1949  26.5 -11.75   19.38     11       0         2\n",
       "3  1949  26.5 -11.50   19.92     13       0         3\n",
       "4  1949  26.5 -11.25   20.13     15       0         3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6f5cdb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30.75, -8.  ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arr = df[(df.mean_t > 14) & (df.mean_t < 15) & (df.time == 2000)][['lat', 'lon']].to_numpy()\n",
    "test_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307bc6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coords(year, min_mean_t = -273.15, max_mean_t = 273.15):\n",
    "    return df[(df.time == year) & (df.mean_t > min_mean_t) & (df.mean_t < max_mean_t)][['lat', 'lon']].to_numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
